{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab\n",
    "import wradlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import stats\n",
    "from matplotlib import animation\n",
    "import matplotlib.patches as mpatches\n",
    "matplotlib.collections import PatchCollection\n",
    "from scipy.ndimage import zoom\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.simplefilter('once', DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read sample data\n",
    "\n",
    "Data is from the German Weather Service: the so called RY product represents rainfall intensity composite for the whole of Germany in 5 minute intervals. \n",
    "\n",
    "Spatial resolution: `1 x 1 km`; spatial extent: `900 x 900 km`.\n",
    "\n",
    "**Information required from user**\n",
    "\n",
    "- specify the directory `datadir` where you store the RY data (unpack the ry archives there).\n",
    "- select a specific interval by commenting/uncommenting the `dtimes` lines.\n",
    "- decide whether you need to reduce the resolution (downsize the image by a `downsizeby`) in order to avoid memory problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set data directory\n",
    "datadir = \"data/ry\"\n",
    "\n",
    "# Original grid dimensions\n",
    "nx = 900\n",
    "ny = 900\n",
    "\n",
    "# pixel size (in meters)\n",
    "dx = 1000.\n",
    "dy = 1000.\n",
    "\n",
    "# Downsize by factor \"downsizeby\"\n",
    "#    downsizeby = 1 will leave the dimensions unchanged,\n",
    "#    but for a 900x900 km grid, downsizing might be \n",
    "#    required in order to avoid MemoryError\n",
    "downsizeby = 1\n",
    "\n",
    "# interval between observations (in seconds)\n",
    "interval = 300\n",
    "\n",
    "# Set time window\n",
    "##dtimes = wradlib.util.from_to(\"2008-06-02 17:00:00\", \"2008-06-02 19:00:00\", interval)\n",
    "##dtimes = wradlib.util.from_to(\"2015-04-26 17:00:00\", \"2015-04-26 19:00:00\", interval)\n",
    "##dtimes = wradlib.util.from_to(\"2015-03-29 17:00:00\", \"2015-03-29 19:00:00\", interval)\n",
    "dtimes = wradlib.util.from_to(\"2016-05-29 16:00:00\", \"2016-05-29 19:00:00\", interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\src\\git\\wradlib\\wradlib\\wradlib\\trafo.py:127: RuntimeWarning: divide by zero encountered in log10\n",
      "  return 10. * np.log10(x)\n"
     ]
    }
   ],
   "source": [
    "# Compute grid dimensions and grid coordinates after resampling\n",
    "dx2, dy2 = dx*downsizeby, dy*downsizeby\n",
    "nx2, ny2 = nx/downsizeby, ny/downsizeby\n",
    "\n",
    "X2, Y2 = np.meshgrid( np.arange(0,nx2*dx2, dx2), np.arange(0,ny2*dy2, dy2) )\n",
    "\n",
    "# Define container\n",
    "frames = np.zeros( (len(dtimes), nx2, ny2 ) )\n",
    "\n",
    "# Read the data, convert back to dBZ, and downsize\n",
    "for i, dtime in enumerate(dtimes):\n",
    "    fname = dtime.strftime( os.path.join(datadir, \"raa01-ry_10000-%y%m%d%H%M-dwd---bin\") )\n",
    "    frames[i] = zoom( wradlib.io.read_RADOLAN_composite(fname, missing=0)[0], 1./downsizeby, order=1)\n",
    "    frames[i] = wradlib.trafo.decibel( wradlib.zr.r2z(frames[i]) )\n",
    "    frames[i][frames[i]<0] = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use OpenCV's Optical Flow to detect and track features\n",
    "\n",
    "This example uses the Lucas-Kanade Optical Flow implementation in OpenCV (see [here](http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_video/py_lucas_kanade/py_lucas_kanade.html)). We take the first frame, detect some Shi-Tomasi corner points in it, then we iteratively track those points over the subsequnet images.\n",
    "\n",
    "The parameter dictionaries are certainly something to experiment with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FEATURE DETECTION: Parameters for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 200,\n",
    "                       qualityLevel = 0.2,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 21 )\n",
    "\n",
    "# FEATURE TRACKING: Parameters for Lucas Kanade (lk) Optical Flow technique\n",
    "lk_params = dict( winSize  = (20,20),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0))\n",
    "\n",
    "# Over which time steps (of the data we've read in) do you want to track\n",
    "trackstart = 0\n",
    "trackend = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Our approach requires 8 bit integers - so we need to normalize our radar data accordingly\n",
    "#   (there might be a more elegant solution...)\n",
    "minval = 0\n",
    "maxval = 59 # dBZ in this case\n",
    "iframes = frames.copy()\n",
    "iframes[iframes<minval] = minval\n",
    "iframes[iframes>maxval] = maxval\n",
    "iframes = ((iframes / maxval)*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 130 good features to track.\n"
     ]
    }
   ],
   "source": [
    "# Find good features to track...\n",
    "old = cv2.goodFeaturesToTrack(iframes[trackstart], mask = None, **feature_params)\n",
    "print \"Found %d good features to track.\" % len(old)\n",
    "\n",
    "# Set containers to collect results (time steps in rows, corners in columns)\n",
    "#   Tracking status\n",
    "sts = np.zeros((trackend,len(old)), dtype=np.bool)\n",
    "sts[0] = True\n",
    "#   corner x coords\n",
    "x = np.zeros((trackend,len(old))) * np.nan\n",
    "x[0] = old[:,0,0]\n",
    "#   corner y coords\n",
    "y = np.zeros((trackend,len(old))) * np.nan\n",
    "y[0] = old[:,0,1]\n",
    "#   tracking error\n",
    "errs = np.zeros((trackend,len(old))) * np.nan\n",
    "errs[0] = 0.\n",
    "#   Assign persistent corner IDs\n",
    "ids = np.arange(len(old))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Track good features\n",
    "for i in range(trackstart+1, trackend):\n",
    "    # track current corners in next image\n",
    "    new, st, err = cv2.calcOpticalFlowPyrLK(prevImg=iframes[i], nextImg=iframes[i+1], prevPts=old, nextPts=None, **lk_params)\n",
    "    success = st.ravel()==1\n",
    "    ids = ids[success]\n",
    "    sts[i, ids] = True\n",
    "    x[i, ids] = new[success,0,0]\n",
    "    y[i, ids] = new[success,0,1]\n",
    "    errs[i, ids] = err.ravel()[success]\n",
    "    #sts = np.vstack( (sts, st.reshape(1,-1).astype(np.bool)))\n",
    "    #cornerx = np.vstack( (cornerx,new[:,0,0].reshape(1,-1)) )\n",
    "    #cornery = np.vstack( (cornery,new[:,0,1].reshape(1,-1)) )\n",
    "    # new corners will be old in the next loop\n",
    "    old = new[success]\n",
    "\n",
    "# Incremental euclidic distance from starting point\n",
    "trackdist = np.diff( np.sqrt( (x-x[0].reshape((1,-1)))**2 + (y-y[0].reshape((1,-1)))**2 ), axis=0 )\n",
    "trackdist = np.vstack( (np.zeros((1,trackdist.shape[1])), trackdist))\n",
    "\n",
    "# Plot feature persistence\n",
    "fig = plt.figure(figsize=(12,6))\n",
    "ax = fig.add_subplot(211)\n",
    "cb = plt.imshow(errs, interpolation=\"none\", cmap=\"summer\", vmax = 15)\n",
    "plt.xlabel(\"Feature ID\")\n",
    "plt.ylabel(\"Tracking time step\")\n",
    "plt.colorbar(cb, shrink=0.5)\n",
    "plt.title(\"Tracking error\")\n",
    "\n",
    "# Plot consistence of movement\n",
    "ax = fig.add_subplot(212)\n",
    "cb = plt.imshow(trackdist, interpolation=\"none\", cmap=\"bwr\", vmin=-5, vmax=5)\n",
    "plt.xlabel(\"Feature ID\")\n",
    "plt.ylabel(\"Tracking time step\")\n",
    "plt.colorbar(cb, shrink=0.5)\n",
    "plt.title(\"Incremental euclidian distance from starting point\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 89 good tracks and 41 bad tracks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\wradlib09\\lib\\site-packages\\ipykernel\\__main__.py:8: RuntimeWarning: invalid value encountered in less\n",
      "C:\\Anaconda3\\envs\\wradlib09\\lib\\site-packages\\ipykernel\\__main__.py:11: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "# Find good tracks (but what is a \"good\" track...?)\n",
    "goodtrack = np.zeros(x.shape[1], dtype=np.bool)\n",
    "for i in range(len(goodtrack)):\n",
    "    # persistence of the track\n",
    "    if len(np.where(sts[:,i])[0]) < 2:\n",
    "        continue\n",
    "    # consistency of movement\n",
    "    if len(np.where(trackdist[:,i]<0)[0]) > 0:\n",
    "        continue\n",
    "    # tracking error\n",
    "    if len(np.where(errs[:,i]>15)[0]) > 5:\n",
    "        continue\n",
    "    goodtrack[i] = True\n",
    "print \"Found %d good tracks and %d bad tracks.\" % (len(np.where(goodtrack)[0]), len(goodtrack)-len(np.where(goodtrack)[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize tracks: white: good track, red: bad track\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, aspect=\"equal\")\n",
    "# average reflectivity as background image\n",
    "ax.imshow(np.mean(frames[trackstart:trackend], axis=0), origin=\"lower\", cmap=\"gray\", interpolation=\"none\")\n",
    "plt.xlabel(\"Easting (# pixels)\")\n",
    "plt.ylabel(\"Northing (# pixels)\")\n",
    "plt.title(\"[Zoom in to inspect track properties]\")\n",
    "plt.grid(color=\"white\")\n",
    "plt.xlim(0,nx/downsizeby)\n",
    "plt.ylim(0,nx/downsizeby)\n",
    "for i, isgood in enumerate(goodtrack):\n",
    "    ix = sts[:,i]\n",
    "    color = \"red\"\n",
    "    if isgood:\n",
    "        color = \"green\"\n",
    "    ax.plot(x[ix,i], y[ix,i],marker=\"None\", color=color, markersize=14, linestyle=\"-\")\n",
    "    ax.arrow(x[ix,i][-2], y[ix,i][-2],\n",
    "             np.diff(x[ix,i][-2:])[0], np.diff(y[ix,i][-2:])[0], \n",
    "             head_width=2, head_length=2, fc=color, ec=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Experiment with feature detection and description\n",
    "\n",
    "We now im at [features](http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_table_of_contents_feature2d/py_table_of_contents_feature2d.html) instead of corners: detection, description, and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1059 keypoints.\n"
     ]
    }
   ],
   "source": [
    "# SIFT\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "kp = sift.detect(iframes[0],None)\n",
    "print \"Found %d keypoints.\" % len(kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PatchCollection at 0x2d58bcc0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111, aspect=\"equal\")\n",
    "# average reflectivity as background image\n",
    "ax.imshow(frames[0], origin=\"lower\", cmap=\"gray\", interpolation=\"none\")\n",
    "plt.xlabel(\"Easting (# pixels)\")\n",
    "plt.ylabel(\"Northing (# pixels)\")\n",
    "plt.title(\"[Zoom in to inspect feature properties]\")\n",
    "plt.grid(color=\"white\")\n",
    "plt.xlim(0,nx/downsizeby)\n",
    "plt.ylim(0,nx/downsizeby)\n",
    "patches = []\n",
    "for kp_ in kp:\n",
    "    if kp_.size > 5:\n",
    "        circle = mpatches.Circle(kp_.pt, kp_.size, fill=False, edgecolor=color)\n",
    "    #ax.add_patch(circle)\n",
    "    patches.append(circle)\n",
    "collection = PatchCollection(patches, facecolor=\"none\", edgecolor=color)\n",
    "ax.add_collection(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
